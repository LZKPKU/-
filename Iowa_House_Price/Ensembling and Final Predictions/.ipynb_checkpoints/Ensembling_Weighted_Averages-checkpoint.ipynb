{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ensembling of Various Models: Voting and Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a kernel on a convoluted Kaggle prediction public leaderboard score.\n",
    "Computed multiple weighted averages in a three-step series of weighted averages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "#options for display\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 120)\n",
    "pd.set_option('display.max_rows', 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train_x.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train_x.values, train_y, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and test data :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('../Data/train_x2.csv')\n",
    "train_y = pd.read_csv('../Data/train_y2.csv',header=None)\n",
    "train_y = train_y.values.ravel()\n",
    "test_x = pd.read_csv('../Data/test_x2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that converts to kaggle submission formatted pandas Dataframe\n",
    "def kaggle(x):\n",
    "    # Input x - the model prediction\n",
    "    # returns dataframe of sales price and Id ready to be written to\n",
    "    # csv for kaggle competition submission.\n",
    "    return(pd.DataFrame({'Id': (np.arange(len(x)) + 1461),\n",
    "                         'SalePrice': np.exp(x)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tiered Sum Weighted Average Kaggle LB Predictor\n",
    "First took a weighted average half and half between Elastic Net and SVR. Then computed a weighted average between that ensembled prediction and lowly weighted GBR and ridge regression. This is a sort of tiered averages where we make a prediction and post it to the Kaggle Leaderboard, then once we decide it's a good score, we continue using those new results and developing another prediction by weighting averages with those predictions and the previous ones from the individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelRidge(alpha=0.6, coef0=2.5, degree=2, gamma=None, kernel='polynomial',\n",
       "      kernel_params=None)"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)  \n",
    "KRR.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.0049, copy_X=True, fit_intercept=True, l1_ratio=0.61,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic = ElasticNet(alpha= 0.0049, fit_intercept = True, l1_ratio= 0.61)\n",
    "elastic.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.01, loss='ls', max_depth=2, max_features=12,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=4000, presort='auto', random_state=42,\n",
       "             subsample=0.7, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 836,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth = 2, max_features = 12, min_samples_split = 10, subsample = 0.7,\n",
    "     random_state=42, learning_rate = 0.01, n_estimators = 4000, verbose = 0)\n",
    "gbr.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.2, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 837,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(alpha = 1.2)\n",
    "ridge.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=9, cache_size=200, coef0=0.0, degree=1, epsilon=0.009, gamma='auto',\n",
       "  kernel='poly', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = svm.SVR(C=9, epsilon=.009, degree = 1, kernel='poly')\n",
    "svr.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1st Normal Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elastic_pred = kaggle(elastic.predict(test_x))\n",
    "svr_pred = kaggle(svr.predict(test_x))\n",
    "KRR_pred = kaggle(KRR.predict(test_x))\n",
    "GBR_pred = kaggle(gbr.predict(test_x))\n",
    "ridge_pred = kaggle(ridge.predict(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing Around with weights to then be tested on Kaggle Public Leaderboard. The best ones found are recorded below, ended with a final public leaderboard score of 0.1154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = elastic_pred\n",
    "pred['SalePrice'] = (0.7*elastic_pred['SalePrice'] + \n",
    "                      0.2*svr_pred['SalePrice'] + \n",
    "                      0.1*ridge_pred['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In case you want to test original weighted average\n",
    "pred.to_csv('KaggleHighestScore.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred2 = pred.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred2['SalePrice'] = 0.7*pred['SalePrice'] + 0.7*elastic_pred['SalePrice']+0.2*KRR_pred['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred2.to_csv('AveragedModel.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Final_Ensemble = pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Final_Ensemble.SalePrice = 0.8*pred2 + 0.15*KRR_pred + 0.05*GBR_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred2.to_csv('EnsembleAveragedModel.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
